{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from abc import ABC, abstractmethod\n",
    "import numpy as np\n",
    "import sklearn.datasets as skd\n",
    "from numpy.random import PCG64\n",
    "from torch import nn, Tensor\n",
    "import torch as torch\n",
    "from tqdm import notebook\n",
    "import unittest\n",
    "%reload_ext ipython_unittest"
   ],
   "id": "6e20f2035688c46c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Flow Matching\n",
    "Let $q$ be a complex target distribution over $\\mathbb{R}^d$. Let $p$ be a simple distribution over the same space that can be easily sampled (for example $p \\sim \\mathcal{N}(0, I)$)\n",
    "\n",
    "### Goal\n",
    "We want to construct a probability path $p_t$ with $t \\in [0,1]$ s.t. $p_0 = p$ and $p_1 = q$. Every $p_t$ is a valid probability density function (PDF).\n",
    "\n",
    "Given a sample $X_0 \\sim p$, the goal is to estimate the corresponding $X_1 \\sim q$ using an Ordinary Differential Equation (ODE).\n",
    "Let $u : [0, 1] \\times \\mathbb{R}^d \\rightarrow \\mathbb{R}^d$ be a *velocity* field $u$ and $\\psi  : [0, 1] \\times \\mathbb{R}^d \\rightarrow \\mathbb{R}^d$ its corresponding *flow*, given by the ODE:\n",
    "$$\n",
    "\\frac{d}{dt}\\psi_t(x) = u_t(\\psi_t(x))\n",
    "$$\n",
    "where $\\psi_t = \\psi(t, x)$ and $\\psi_0(x) = x$\n"
   ],
   "id": "ed67199903033b90"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def euler(x_t, h, direction):\n",
    "    return x_t + h * direction\n",
    "\n",
    "\n",
    "class InterpolationMethod(ABC):\n",
    "    @classmethod\n",
    "    @abstractmethod\n",
    "    def apply(cls, t: Tensor, x_0: Tensor, x_1: Tensor):\n",
    "        \"\"\"Returns the random variable X_t.\"\"\"\n",
    "        pass\n",
    "\n",
    "\n",
    "class OptimalTransport(InterpolationMethod):\n",
    "    \"\"\"Uses the L2-norm optimal transport.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def apply(self, t, x_0, x_1):\n",
    "        return (1 - t) * x_0 + t * x_1\n",
    "\n",
    "\n",
    "class FlowMatching(nn.Module):\n",
    "    \"\"\"A simple MLP, representing a parametrized velocity field.\"\"\"\n",
    "\n",
    "    def __init__(self, input_dim=3, hidden_dim=256, output_dim=2, n_layers=4, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "        layers = [nn.Linear(input_dim, hidden_dim), nn.GELU()]\n",
    "        for _ in range(n_layers - 1):\n",
    "            layers.extend([nn.Linear(hidden_dim, hidden_dim), nn.GELU()])\n",
    "        layers.append(nn.Linear(hidden_dim, output_dim))\n",
    "\n",
    "        self.network = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, t, x):\n",
    "        tx_input = torch.cat((t, x), -1)\n",
    "        return self.network(tx_input)\n",
    "\n",
    "\n",
    "def sample_from_p(n):\n",
    "    return torch.tensor(RNG.multivariate_normal(mean=np.zeros(2), cov=np.eye(2), size=n)).float()\n",
    "\n",
    "\n",
    "def sample_from_q(n):\n",
    "    sample = torch.from_numpy(skd.make_moons(n_samples=n, noise=0.005)[0]).float()\n",
    "    angle_rad = 45 * np.pi / 180  # Convert angle to radians\n",
    "    c, s = np.cos(angle_rad), np.sin(angle_rad)\n",
    "\n",
    "    rotation_matrix = torch.tensor([[2 * c, -s],\n",
    "                                    [s, 2 * c]], dtype=torch.float32)\n",
    "    rotated_sample = sample @ rotation_matrix\n",
    "    return rotated_sample + torch.tensor(SHIFT_TARGET_BY)"
   ],
   "id": "b50eaafc4fde8f7a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "%%unittest_main\n",
    "\n",
    "# Test for the optimal transport.\n",
    "\n",
    "\n",
    "class TestOptimalTransport(unittest.TestCase):\n",
    "    def test_simple(self):\n",
    "        x_0 = Tensor((0, 0, 0, 0, 0))\n",
    "        x_1 = Tensor((1, 1, 1, 1, 1))\n",
    "        t = Tensor((0, 0.25, 0.5, 0.75, 1))\n",
    "        usedMethod = OptimalTransport()\n",
    "        actual = usedMethod.apply(t, x_0, x_1)\n",
    "        self.assertTrue(torch.equal(actual, Tensor([0, 0.25, 0.5, 0.75, 1])))\n",
    "\n",
    "    def test_2d(self):\n",
    "        x_0 = Tensor([[0, 0, 0, 0, 0],\n",
    "                      [0, 0, 0, 0, 0]])\n",
    "        x_1 = Tensor([[1, 1, 1, 1, 1],\n",
    "                      [2, 2, 2, 2, 2]])\n",
    "        t = Tensor([0, 0.25, 0.5, 0.75, 1])\n",
    "        usedMethod = OptimalTransport()\n",
    "        actual = usedMethod.apply(t, x_0, x_1)\n",
    "        expected = Tensor([[0.0, 0.25, 0.5, 0.75, 1.0],\n",
    "                           [0.0, 0.5, 1.0, 1.5, 2.0]])\n",
    "        self.assertTrue(torch.equal(actual, expected))"
   ],
   "id": "5d75969151cfe510"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "SHIFT_TARGET_BY = [4, 4]\n",
    "SOLVER = euler\n",
    "\n",
    "PATH_DESIGN = OptimalTransport()\n",
    "RNG = np.random.Generator(PCG64(seed=44))\n",
    "N_TEST_SAMPLES = 100\n"
   ],
   "id": "4119598329635eb8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "EPOCHS = 10000\n",
    "BATCH_SIZE = 2000\n",
    "LR = 1e-3\n",
    "\n",
    "model = FlowMatching()  # Simple MLP.\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n",
    "loss = nn.MSELoss()\n",
    "\n",
    "for epoch in notebook.tqdm(range(EPOCHS)):\n",
    "    x_0 = sample_from_p(BATCH_SIZE)\n",
    "    x_1 = sample_from_q(BATCH_SIZE)\n",
    "    t = torch.rand(BATCH_SIZE, 1)  # Sample t randomly from [0, 1].\n",
    "\n",
    "    x_t = (1 - t) * x_0 + t * x_1\n",
    "\n",
    "    # Get velocity prediction\n",
    "    v_predicted = model(t, x_t)\n",
    "    difference = x_1 - x_0\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss(v_predicted, difference).backward()\n",
    "    optimizer.step()"
   ],
   "id": "561c18e1bc17a498"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "trajectories = []\n",
    "INFERENCE_STEPS = 50\n",
    "test_data = sample_from_p(1)\n",
    "x_t = test_data\n",
    "delta_t = 1 / INFERENCE_STEPS\n",
    "\n",
    "# Forward trajectory for an unseen noisy test sample.\n",
    "with torch.no_grad():\n",
    "    for current_step in range(INFERENCE_STEPS):\n",
    "        t = delta_t * current_step\n",
    "        t_tensor = torch.full((x_t.shape[0], 1), t)\n",
    "        v_pred = model(t_tensor.float(), x_t.float())\n",
    "        x_t = euler(x_t, delta_t, v_pred)\n",
    "        trajectories.append(x_t)"
   ],
   "id": "6006ee7ca9d39cdc"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## The following cells for creating visualizations have mostly been created using Generative AI.",
   "id": "9753ffc312019153"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "fm_model = model",
   "id": "4152f77357020a46"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# Generate samples for visualization\n",
    "N_SAMPLES = 2000\n",
    "initial_noise_samples = sample_from_p(N_SAMPLES).numpy()\n",
    "target_data_samples = sample_from_q(N_SAMPLES).numpy()\n",
    "\n",
    "# --- MODIFIED: Switched to the object-oriented API for more control ---\n",
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "\n",
    "ax.set_title(\"Noise and Target Distributions\", fontsize=16)\n",
    "ax.set_xlabel(\"x\", fontsize=12)\n",
    "ax.set_ylabel(\"y\", fontsize=12)\n",
    "\n",
    "# Plot the initial noise distribution\n",
    "ax.scatter(initial_noise_samples[:, 0], initial_noise_samples[:, 1],\n",
    "           color='red', alpha=0.3, s=20, label=r'p ~ $\\mathcal{N}\\:(0, \\text{I})$')\n",
    "\n",
    "# Plot the target data distribution\n",
    "ax.scatter(target_data_samples[:, 0], target_data_samples[:, 1],\n",
    "           color='blue', alpha=0.3, s=20, label=r'$q$')\n",
    "\n",
    "# Set consistent plot limits\n",
    "ax.set_xlim([-4, 8])\n",
    "ax.set_ylim([-4, 8])\n",
    "\n",
    "# Explicitly set the ticks to ensure the full range is shown\n",
    "ticks = np.arange(-4, 9, 2)\n",
    "ax.set_xticks(ticks)\n",
    "ax.set_yticks(ticks)\n",
    "\n",
    "ax.grid(True, which='both', linestyle='--', linewidth=0.5)\n",
    "\n",
    "# --- THE FIX: Use ax.set_aspect() instead of plt.axis('equal') ---\n",
    "# This enforces the aspect ratio without changing the data limits.\n",
    "ax.set_aspect('equal', adjustable='box')\n",
    "\n",
    "ax.legend(loc='upper left', fontsize=12)\n",
    "plt.savefig(\"noise_and_target.png\", dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ],
   "id": "684142172371df24"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# This cell contains all the necessary components for the diffusion model.\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "\n",
    "class DiffusionScheduler:\n",
    "    def __init__(self, num_timesteps=1000, beta_start=0.0001, beta_end=0.02):\n",
    "        self.num_timesteps = num_timesteps\n",
    "        self.betas = torch.linspace(beta_start, beta_end, num_timesteps)\n",
    "        self.alphas = 1. - self.betas\n",
    "        self.alphas_cumprod = torch.cumprod(self.alphas, axis=0)\n",
    "        self.sqrt_alphas_cumprod = torch.sqrt(self.alphas_cumprod)\n",
    "        self.sqrt_one_minus_alphas_cumprod = torch.sqrt(1. - self.alphas_cumprod)\n",
    "\n",
    "    def add_noise(self, x_start, t, noise):\n",
    "        sqrt_alpha_t = self.sqrt_alphas_cumprod[t].view(-1, 1)\n",
    "        sqrt_one_minus_alpha_t = self.sqrt_one_minus_alphas_cumprod[t].view(-1, 1)\n",
    "        return sqrt_alpha_t * x_start + sqrt_one_minus_alpha_t * noise\n",
    "\n",
    "\n",
    "# This cell defines an improved DenoiseModel with a larger hidden dimension.\n",
    "\n",
    "class DenoiseModel(nn.Module):\n",
    "    # Increased hidden_dim from 128 to 256 for more capacity\n",
    "    def __init__(self, input_dim=2, time_emb_dim=32, hidden_dim=256):\n",
    "        super().__init__()\n",
    "        self.time_mlp = nn.Sequential(nn.Linear(time_emb_dim, hidden_dim), nn.GELU(), nn.Linear(hidden_dim, hidden_dim))\n",
    "        self.network = nn.Sequential(\n",
    "            nn.Linear(input_dim + hidden_dim, hidden_dim), nn.GELU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim), nn.GELU(),\n",
    "            nn.Linear(hidden_dim, input_dim)\n",
    "        )\n",
    "        self.time_emb_dim = time_emb_dim\n",
    "\n",
    "    def forward(self, x, t):\n",
    "        half_dim = self.time_emb_dim // 2\n",
    "        emb = np.log(10000) / (half_dim - 1)\n",
    "        emb = torch.exp(torch.arange(half_dim) * -emb)\n",
    "        emb = t[:, None] * emb[None, :]\n",
    "        time_emb = self.time_mlp(torch.cat((emb.sin(), emb.cos()), dim=1))\n",
    "        xt_input = torch.cat([x, time_emb], dim=-1)\n",
    "        return self.network(xt_input)\n",
    "\n",
    "\n",
    "# The training function remains the same but will now use the updated model class.\n",
    "def train_diffusion_model(epochs=10000, batch_size=2048):\n",
    "    print(\"--- Training Diffusion Model ---\")\n",
    "    model = DenoiseModel()  # Instantiates the new, larger model\n",
    "    scheduler = DiffusionScheduler()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "    loss_fn = nn.MSELoss()\n",
    "\n",
    "    for epoch in notebook.tqdm(range(epochs), desc=\"Training DM\"):\n",
    "        x_start = sample_from_q(batch_size)\n",
    "        t = torch.randint(0, scheduler.num_timesteps, (batch_size,))\n",
    "        noise = torch.randn_like(x_start)\n",
    "        x_noisy = scheduler.add_noise(x_start, t, noise)\n",
    "        noise_pred = model(x_noisy, t.float())\n",
    "        loss = loss_fn(noise_pred, noise)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(\"Diffusion training complete!\\n\")\n",
    "    return model, scheduler"
   ],
   "id": "b0aa84d891017887"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Re-train the improved diffusion model with more epochs for better convergence.\n",
    "DIFFUSION_EPOCHS = 30000\n",
    "\n",
    "# This assumes 'fm_model' is already trained and available.\n",
    "diff_model, diff_scheduler = train_diffusion_model(epochs=DIFFUSION_EPOCHS)"
   ],
   "id": "21f7ed72da54c358"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# This function generates the high-quality \"noise-to-data\" (denoising) trajectory for the diffusion model.\n",
    "\n",
    "@torch.no_grad()\n",
    "def generate_diffusion_generative_trajectory(model, scheduler, initial_noise, num_frames):\n",
    "    \"\"\"\n",
    "    Generates a high-quality trajectory by running the FULL denoising process\n",
    "    and then selecting a subset of frames for the animation.\n",
    "    \"\"\"\n",
    "    x_t = initial_noise.clone()\n",
    "\n",
    "    # This list will store the entire 1000-step history\n",
    "    full_trajectory = [x_t.clone()]\n",
    "\n",
    "    # Run the complete denoising loop from T-1 down to 0\n",
    "    for t_step in range(scheduler.num_timesteps - 1, -1, -1):\n",
    "        t = torch.full((initial_noise.shape[0],), t_step, dtype=torch.long)\n",
    "        pred_noise = model(x_t, t.float())\n",
    "\n",
    "        alpha_t = scheduler.alphas[t].view(-1, 1)\n",
    "        alpha_t_cumprod = scheduler.alphas_cumprod[t].view(-1, 1)\n",
    "        beta_t = scheduler.betas[t].view(-1, 1)\n",
    "\n",
    "        mean = (1 / torch.sqrt(alpha_t)) * (x_t - (beta_t / torch.sqrt(1 - alpha_t_cumprod)) * pred_noise)\n",
    "\n",
    "        if t_step > 0:\n",
    "            x_t = mean + torch.sqrt(beta_t) * torch.randn_like(x_t)\n",
    "        else:\n",
    "            x_t = mean\n",
    "\n",
    "        full_trajectory.append(x_t.clone())\n",
    "\n",
    "    # Now, select 'num_frames' evenly spaced samples from the full history\n",
    "    indices_to_sample = np.linspace(0, len(full_trajectory) - 1, num_frames, dtype=int)\n",
    "\n",
    "    # Create the final animation trajectory\n",
    "    animation_trajectory = torch.stack([full_trajectory[i] for i in indices_to_sample])\n",
    "\n",
    "    return animation_trajectory"
   ],
   "id": "645a6f5ab786fb20"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "\n",
    "# --- 1. Setup the Simulation ---\n",
    "N_STEPS = 5\n",
    "DT = 1.0 / N_STEPS\n",
    "\n",
    "# Set a fixed starting point\n",
    "x_0_single = torch.tensor([[2.123, -1.9]])\n",
    "\n",
    "# --- Create a directory to save the plots ---\n",
    "output_folder = 'trajectory_steps'\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# --- 2. Run the 5-Step Generation Process ---\n",
    "x_current = x_0_single.clone()\n",
    "x_history = [x_current.numpy()]\n",
    "v_history = []\n",
    "displacement_history = []\n",
    "\n",
    "for i in range(N_STEPS):\n",
    "    t_tensor = torch.tensor([[i * DT]])\n",
    "    with torch.no_grad():\n",
    "        v_current = fm_model(t_tensor, x_current)\n",
    "\n",
    "    displacement = v_current * DT\n",
    "    x_next = x_current + displacement\n",
    "\n",
    "    v_history.append(v_current.numpy())\n",
    "    displacement_history.append(displacement.numpy())\n",
    "    x_history.append(x_next.numpy())\n",
    "\n",
    "    x_current = x_next\n",
    "\n",
    "# --- 3. Generate and Save Each Plot Individually ---\n",
    "q_samples = sample_from_q(500).numpy()\n",
    "full_path = np.concatenate(x_history)\n",
    "\n",
    "# Loop 6 times for 6 plots (5 steps + 1 final state)\n",
    "for i in range(N_STEPS + 1):\n",
    "    # Create a new figure and axes for each individual plot\n",
    "    fig, ax = plt.subplots(figsize=(8, 8))\n",
    "\n",
    "    # Common plot configuration\n",
    "    ax.set_xlim([-4, 8])\n",
    "    ax.set_ylim([-4, 8])\n",
    "    ax.set_aspect('equal', adjustable='box')\n",
    "    ax.grid(True, linestyle='--', alpha=0.6)\n",
    "    ax.scatter(q_samples[:, 0], q_samples[:, 1], alpha=0.1, color='blue')\n",
    "\n",
    "    # Logic for intermediate steps vs. the final plot\n",
    "    if i < N_STEPS:\n",
    "        # This is one of the first 5 steps\n",
    "        current_time = i * DT\n",
    "        ax.set_title(f\"At t = {current_time:.2f} (Planning Step {i + 1})\", fontsize=14)\n",
    "\n",
    "        # Plot trajectory so far, current position, and next step vector\n",
    "        path_so_far = full_path[:i + 1]\n",
    "        traj_label = 'Trajectory So Far' if i > 0 else None\n",
    "        ax.plot(path_so_far[:, 0], path_so_far[:, 1], 'k--', alpha=0.6, linewidth=1.5, label=traj_label)\n",
    "\n",
    "        x_i = x_history[i].flatten()\n",
    "        disp_i = displacement_history[i].flatten()\n",
    "        ax.scatter(x_i[0], x_i[1], c='black', s=80, zorder=10, label=r'Current Position ($X_t$)')\n",
    "        ax.quiver(x_i[0], x_i[1], disp_i[0], disp_i[1], color='red', scale_units='xy', scale=1, width=0.005,\n",
    "                  label=r'Next Step ($v^{\\theta}_t \\cdot \\Delta{t}$)')\n",
    "    else:\n",
    "        # This is the final plot (t=1.0)\n",
    "        ax.set_title(\"Final Position (t = 1.00)\", fontsize=14)\n",
    "\n",
    "        # Plot full trajectory and final position\n",
    "        ax.plot(full_path[:, 0], full_path[:, 1], 'k--', alpha=0.6, linewidth=1.5, label='Full Trajectory')\n",
    "        x_final = x_history[-1].flatten()\n",
    "        ax.scatter(x_final[0], x_final[1], c='blue', s=100, zorder=10, edgecolors='black',\n",
    "                   label=r'Final Position ($X_1$)')\n",
    "\n",
    "    ax.legend(loc='upper left')\n",
    "\n",
    "    # Save the figure to the specified folder\n",
    "    filename = os.path.join(output_folder, f'step_{i + 1}.png')\n",
    "    plt.savefig(filename, dpi=150, bbox_inches='tight')\n",
    "    plt.close(fig)  # Close the figure to free up memory and prevent it from displaying in the notebook\n",
    "\n",
    "print(f\"✅ Saved {N_STEPS + 1} plots to the '{output_folder}' directory.\")"
   ],
   "id": "f9704aa503c7e4d2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# SINGLE FLOW MATCHING ANIMATION\n",
    "\n",
    "import matplotlib.animation as animation\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "# --- 1. Global Configuration ---\n",
    "N_ANIMATION_SAMPLES = 500\n",
    "FRAMES = 120\n",
    "FILENAME_SINGLE = 'flow_matching_scaled_field_alt.mp4'\n",
    "PLOT_MIN, PLOT_MAX = -4, 8\n",
    "GRID_DENSITY = 18\n",
    "\n",
    "\n",
    "# --- 2. Trajectory Generation ---\n",
    "@torch.no_grad()\n",
    "def generate_flow_trajectory(model, initial_noise, num_frames):\n",
    "    \"\"\"Simulates particle flow from t=0 to t=1 and returns the full trajectory.\"\"\"\n",
    "    trajectory = torch.zeros((num_frames, initial_noise.shape[0], 2))\n",
    "    x_t = initial_noise.clone()\n",
    "    trajectory[0] = x_t\n",
    "    dt = 1.0 / (num_frames -1)\n",
    "\n",
    "    for i in range(num_frames - 1):\n",
    "        t = torch.full((initial_noise.shape[0], 1), i * dt)\n",
    "        velocity = model(t.float(), x_t.float())\n",
    "        x_t += velocity * dt  # Simple Euler integration\n",
    "        trajectory[i + 1] = x_t\n",
    "    return trajectory.numpy()\n",
    "\n",
    "\n",
    "# --- 3. Animation Helper Functions ---\n",
    "def setup_animation_axis(ax, target_samples, particle_color, particle_label):\n",
    "    \"\"\"Configures a subplot for animation and returns handles to dynamic artists.\"\"\"\n",
    "    ax.set_xlim(PLOT_MIN, PLOT_MAX)\n",
    "    ax.set_ylim(PLOT_MIN, PLOT_MAX)\n",
    "    ax.set_aspect('equal', adjustable='box')\n",
    "    ax.grid(True, linestyle='--', alpha=0.6)\n",
    "    ax.set_xlabel(\"x coordinate\", fontsize=12)\n",
    "    ax.set_ylabel(\"y coordinate\", fontsize=12)\n",
    "    ax.scatter(target_samples[:, 0], target_samples[:, 1], alpha=0.15, s=15, color='blue', label='Target')\n",
    "    scatter = ax.scatter([], [], alpha=0.7, s=15, color=particle_color, label=particle_label)\n",
    "    title = ax.set_title('', fontsize=14)\n",
    "    ax.legend(loc='upper left')\n",
    "    return scatter, title\n",
    "\n",
    "\n",
    "def setup_vector_field(ax, model, dt):\n",
    "    \"\"\"Creates, initializes, and returns the quiver plot for the vector field.\"\"\"\n",
    "    x_grid = torch.linspace(PLOT_MIN, PLOT_MAX, GRID_DENSITY)\n",
    "    y_grid = torch.linspace(PLOT_MIN, PLOT_MAX, GRID_DENSITY)\n",
    "    X_grid, Y_grid = torch.meshgrid(x_grid, y_grid, indexing='xy')\n",
    "    grid_points = torch.stack([X_grid.reshape(-1), Y_grid.reshape(-1)], dim=-1).float()\n",
    "    t0 = torch.full((grid_points.shape[0], 1), 0.0)\n",
    "    v_field_0 = model(t0, grid_points).detach() * dt\n",
    "    quiver = ax.quiver(\n",
    "        grid_points[:, 0], grid_points[:, 1], v_field_0[:, 0], v_field_0[:, 1],\n",
    "        color='green', alpha=0.2, scale_units='xy', scale=1,\n",
    "        width=0.003, headwidth=5, headlength=5\n",
    "    )\n",
    "    return quiver, grid_points\n",
    "\n",
    "\n",
    "def update_vector_field(quiver, model, grid_points, t, dt):\n",
    "    \"\"\"Updates the vector field's arrows for the current time t.\"\"\"\n",
    "    t_tensor = torch.full((grid_points.shape[0], 1), t)\n",
    "    v_field = model(t_tensor.float(), grid_points.float()).detach() * dt\n",
    "    quiver.set_UVC(v_field[:, 0], v_field[:, 1])\n",
    "\n",
    "\n",
    "def save_animation_to_file(fig, update_func, num_frames, filename):\n",
    "    \"\"\"Generates and saves the final animation video file.\"\"\"\n",
    "    print(f\"Creating animation for {filename}... This may take a moment. ⏳\")\n",
    "    ani = animation.FuncAnimation(fig, update_func, frames=num_frames, blit=True, interval=50)\n",
    "    try:\n",
    "        ani.save(filename, writer='ffmpeg', fps=30, dpi=120)\n",
    "        print(f\"Animation saved successfully as '{filename}' ✅\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving animation: {e}\\nPlease ensure ffmpeg is installed.\")\n",
    "    plt.close(fig)\n",
    "\n",
    "\n",
    "# --- 4. Main Function for Single Animation ---\n",
    "def create_single_animation(model, trajectory, target_samples, filename):\n",
    "    \"\"\"Creates a single animation of particle flow with its vector field.\"\"\"\n",
    "    fig, ax = plt.subplots(figsize=(8, 8))\n",
    "    dt = 1.0 / (len(trajectory) - 1)\n",
    "    scatter, title = setup_animation_axis(ax, target_samples, 'red', r'$p_t(x)$ Samples')\n",
    "    quiver, grid_points = setup_vector_field(ax, model, dt)\n",
    "\n",
    "    def update(frame):\n",
    "        current_t = frame * dt\n",
    "        scatter.set_offsets(trajectory[frame])\n",
    "        title.set_text(f'Flow Matching Transformation\\nTime t = {current_t:.2f}')\n",
    "        update_vector_field(quiver, model, grid_points, current_t, dt)\n",
    "        return scatter, title, quiver\n",
    "\n",
    "    save_animation_to_file(fig, update, num_frames=len(trajectory), filename=filename)\n",
    "\n",
    "# --- 5. Execution for Single Animation ---\n",
    "# Note: Assumes `sample_from_p`, `sample_from_q`, and `model` are pre-defined.\n",
    "x_0_samples = sample_from_p(N_ANIMATION_SAMPLES)\n",
    "x_1_samples = sample_from_q(N_ANIMATION_SAMPLES)\n",
    "fm_trajectory = generate_flow_trajectory(model, x_0_samples, num_frames=FRAMES)\n",
    "create_single_animation(model, fm_trajectory, x_1_samples, FILENAME_SINGLE)\n",
    "display(Markdown(f\"### [Download Animation]({FILENAME_SINGLE})\"))"
   ],
   "id": "5603f4434531169e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# --- 1. Reusable Helper from Cell 1 ---\n",
    "def add_pause_frames(trajectory, num_pause_frames):\n",
    "    \"\"\"Appends the last frame multiple times to a trajectory to create a pause.\"\"\"\n",
    "    last_frame = trajectory[-1:, :, :]  # Keep dimension\n",
    "    pause_frames = np.repeat(last_frame, num_pause_frames, axis=0)\n",
    "    return np.concatenate([trajectory, pause_frames], axis=0)\n",
    "\n",
    "\n",
    "# --- 2. Main Comparison Animation Function ---\n",
    "def create_comparison_animation(fm_model, fm_traj, dm_traj, target_samples, diff_scheduler, filename,\n",
    "                                num_original_frames):\n",
    "    \"\"\"Creates a side-by-side animation comparing Flow Matching and Diffusion.\"\"\"\n",
    "    fig, (ax_fm, ax_dm) = plt.subplots(1, 2, figsize=(16, 8))\n",
    "    fig.subplots_adjust(wspace=0.25)\n",
    "\n",
    "    dt_fm = 1.0 / (num_original_frames - 1)\n",
    "\n",
    "    # Setup Flow Matching (left) plot using helpers\n",
    "    scatter_fm, title_fm = setup_animation_axis(ax_fm, target_samples, 'red', 'FM Samples')\n",
    "    quiver_fm, grid_points_fm = setup_vector_field(ax_fm, fm_model, dt_fm)\n",
    "\n",
    "    # Setup Diffusion (right) plot using helpers\n",
    "    scatter_dm, title_dm = setup_animation_axis(ax_dm, target_samples, 'purple', 'DM Samples')\n",
    "\n",
    "    def update(frame):\n",
    "        # Determine the effective frame to handle the end-of-animation pause\n",
    "        effective_frame = min(frame, num_original_frames - 1)\n",
    "\n",
    "        # --- Update Flow Matching Plot (Left) ---\n",
    "        current_t_fm = effective_frame * dt_fm\n",
    "        scatter_fm.set_offsets(fm_traj[frame])\n",
    "        title_fm.set_text(f'Flow Matching\\nTime t = {current_t_fm:.2f}')\n",
    "        update_vector_field(quiver_fm, fm_model, grid_points_fm, current_t_fm, dt_fm)\n",
    "\n",
    "        # --- Update Diffusion Plot (Right) ---\n",
    "        timesteps = np.linspace(diff_scheduler.num_timesteps - 1, 0, num_original_frames)\n",
    "        current_t_dm = int(timesteps[effective_frame])\n",
    "        scatter_dm.set_offsets(dm_traj[frame])\n",
    "        title_dm.set_text(f'Diffusion\\nStep t = {current_t_dm}')\n",
    "\n",
    "        return scatter_fm, title_fm, quiver_fm, scatter_dm, title_dm\n",
    "\n",
    "    # Generate and save using the helper\n",
    "    save_animation_to_file(fig, update, num_frames=len(fm_traj), filename=filename)\n",
    "\n",
    "\n",
    "# --- 3. Execution for Comparison Animation ---\n",
    "# Note: Assumes models and schedulers like `fm_model`, `diff_model`, etc. are pre-defined.\n",
    "FILENAME_COMPARISON = 'fm_vs_diffusion_generative.mp4'\n",
    "\n",
    "# Generate a shared set of initial noise for a fair comparison\n",
    "initial_noise = sample_from_p(N_ANIMATION_SAMPLES)\n",
    "target_samples_viz = sample_from_q(N_ANIMATION_SAMPLES)\n",
    "\n",
    "# Generate trajectories for both models\n",
    "print(\"Generating trajectories for comparison animation...\")\n",
    "fm_trajectory = generate_flow_trajectory(fm_model, initial_noise, FRAMES)\n",
    "dm_trajectory = generate_diffusion_generative_trajectory(diff_model, diff_scheduler, initial_noise, FRAMES).numpy()\n",
    "\n",
    "# Create the final animation\n",
    "create_comparison_animation(\n",
    "    fm_model, fm_trajectory, dm_trajectory, target_samples_viz,\n",
    "    diff_scheduler, FILENAME_COMPARISON, num_original_frames=FRAMES\n",
    ")\n",
    "display(Markdown(f\"### [Download Animation]({FILENAME_COMPARISON})\"))"
   ],
   "id": "141cbda84c9b4b25"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "# --- 1. New Helper Functions for Path Tracing ---\n",
    "def setup_trajectory_traces(ax, num_samples, color):\n",
    "    \"\"\"Initializes and returns a list of line objects for tracing paths.\"\"\"\n",
    "    return [ax.plot([], [], color=color, alpha=0.25, linewidth=0.7)[0] for _ in range(num_samples)]\n",
    "\n",
    "def update_trajectory_traces(lines, full_trajectory, current_frame):\n",
    "    \"\"\"Updates the data for each line to trace the path up to the current frame.\"\"\"\n",
    "    for i, line in enumerate(lines):\n",
    "        path_so_far = full_trajectory[:current_frame + 1, i, :]\n",
    "        line.set_data(path_so_far[:, 0], path_so_far[:, 1])\n",
    "\n",
    "# --- 2. Main Animation Function with Tracing ---\n",
    "def create_comparison_animation_with_traces(fm_model, fm_traj, dm_traj, target_samples, diff_scheduler, filename):\n",
    "    \"\"\"Creates a side-by-side animation that traces each particle's path.\"\"\"\n",
    "    fig, (ax_fm, ax_dm) = plt.subplots(1, 2, figsize=(16, 8), sharex=True, sharey=True)\n",
    "    fig.subplots_adjust(wspace=0.25)\n",
    "\n",
    "    num_frames = fm_traj.shape[0]\n",
    "    num_samples = fm_traj.shape[1]\n",
    "    dt_fm = 1.0 / (num_frames - 1)\n",
    "\n",
    "    # Setup Flow Matching (left) plot using helpers\n",
    "    scatter_fm, title_fm = setup_animation_axis(ax_fm, target_samples, 'red', 'Samples')\n",
    "    quiver_fm, grid_points_fm = setup_vector_field(ax_fm, fm_model, dt_fm)\n",
    "    fm_lines = setup_trajectory_traces(ax_fm, num_samples, 'red')\n",
    "\n",
    "    # Setup Diffusion (right) plot using helpers\n",
    "    scatter_dm, title_dm = setup_animation_axis(ax_dm, target_samples, 'purple', 'Samples')\n",
    "    dm_lines = setup_trajectory_traces(ax_dm, num_samples, 'purple')\n",
    "\n",
    "    def update(frame):\n",
    "        # --- Update Titles and Scatter Positions ---\n",
    "        current_t_fm = frame * dt_fm\n",
    "        title_fm.set_text(f'Flow Matching\\nTime t = {current_t_fm:.2f}')\n",
    "        scatter_fm.set_offsets(fm_traj[frame])\n",
    "\n",
    "        timesteps = np.linspace(diff_scheduler.num_timesteps - 1, 0, num_frames)\n",
    "        current_t_dm = int(timesteps[frame])\n",
    "        title_dm.set_text(f'Diffusion\\nStep t = {current_t_dm}')\n",
    "        scatter_dm.set_offsets(dm_traj[frame])\n",
    "\n",
    "        # --- Update Vector Field and Traces ---\n",
    "        update_vector_field(quiver_fm, fm_model, grid_points_fm, current_t_fm, dt_fm)\n",
    "        update_trajectory_traces(fm_lines, fm_traj, frame)\n",
    "        update_trajectory_traces(dm_lines, dm_traj, frame)\n",
    "\n",
    "        # Return all artists that have been updated for blitting\n",
    "        return (scatter_fm, title_fm, quiver_fm, scatter_dm, title_dm, *fm_lines, *dm_lines)\n",
    "\n",
    "    # Generate and save using the main helper\n",
    "    save_animation_to_file(fig, update, num_frames=num_frames, filename=filename)\n",
    "\n",
    "# --- 3. Main Execution for Traced Comparison ---\n",
    "FILENAME_TRACED = 'fm_vs_diffusion_traced.mp4'\n",
    "\n",
    "# Generate trajectories starting from the same initial noise\n",
    "print(\"\\nGenerating trajectories for traced animation...\")\n",
    "initial_noise = sample_from_p(N_ANIMATION_SAMPLES)\n",
    "target_samples_viz = sample_from_q(N_ANIMATION_SAMPLES)\n",
    "\n",
    "fm_trajectory = generate_flow_trajectory(fm_model, initial_noise, FRAMES)\n",
    "dm_trajectory = generate_diffusion_generative_trajectory(diff_model, diff_scheduler, initial_noise, FRAMES).numpy()\n",
    "\n",
    "\n",
    "# Create the final animation with traced paths\n",
    "create_comparison_animation_with_traces(\n",
    "    fm_model, fm_trajectory, dm_trajectory, target_samples_viz,\n",
    "    diff_scheduler, FILENAME_TRACED\n",
    ")\n",
    "\n",
    "display(Markdown(f\"### [Download Animation]({FILENAME_TRACED})\"))"
   ],
   "id": "ee50341e24713610"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "!ffmpeg -y -i fm_vs_diffusion_traced.mp4 -vf tpad=stop_mode=clone:stop_duration=1 long_fm_vs_diffusion_traced.mp4",
   "id": "eb06339dee57973d"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
